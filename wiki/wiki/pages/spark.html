<html>
	<head>
		<title>Wiki</title>
		 <link rel=stylesheet href=../wiki.css>
		 <link rel=icon href=icon.jpg>
	</head>
	<body>
		<h1>Python Spark</h1>
		<p><code>from pyspark.sql import functions as f</code></p>
		<p><code>from pyspark.sql.types import *</code></p>
		<h3>Read from .csv</h3>
		<p><code>df = spark.read.options(header=True, inferSchema=True).csv("dataframe.csv")</code></p>
		<h3>Write to .csv</h3>
		<p><code>df.repartition(1).write.csv('/mnt/dataframe.csv', header = True)</code></p>
		<h3>Dataframe creation</h3>
		<p>	
			<code>schema = StructType(</code></br>
			<code>    [StructField("age", IntegerType()),</code></br>
			<code>    StructField("rt", LongType()),</code></br>
			<code>    StructField("ccod", StringType()),</code></br>
			<code>    StructField("label", IntegerType())])</code></br></br>
			<code>data = [[20, 1549974188869, 'US', 1],</code></br>
			<code>    [None, None, 'US', 1],</code></br>
			<code>    [80, 1549972905314, 'US', 0]]</code></br>
			<code>df = spark.createDataFrame(data, schema=schema)</code></br>
		</p>
		<h3>Dataframe iteration</h3>
		<p>	
			<code>for row in df.rdd.collect():</code></br>
			<code>    print(row)</code></br>
			<code>    print(row['column'])</code></br>
		</p>

		<h3>Dataframe exploration</h3>
		<p>	
			<code>print(df.count(), len(df.columns))</code></br>
			<code>print(df.columns, df.dtypes)</code></br>
			<code>df.show(20)</code></br>
			<code>df.limit(20)</code></br>
			<code>df.sample(False, 0.1)</code>
		</p>
		<h3>Dataframe columns</h3>
		<p>	
			<code>df.select('column_name')</code></br>
			<code>df.select('struct_name.*')</code></br>
			<code>df.select(df.sid, f.explode(df.dpi).alias("dpi")).select(df.sid, "dpi.*")</code>
		</p>
		<h3>Dataframe filtering</h3>
		<p>	
			<code>df.where(f.col('dpi.dpt').isNull())</code></br>
			<code>df.where(f.col('dpi.dpt').isNotNull())</code></br>
			<code>df.where((f.col('dpi.dpt') == 'DSP') & (f.col("ATC.curated") == False))</code>
		</p>
		<h3>Replacing columns based on condition</h3>
		<p>	
			<code>df.withColumn('ccod', f.when(f.col('ccod') == '', 'Empty').otherwise(f.col('ccod')))</code></br>
		</p>
		<h3>Filling null values</h3>
		<p>	
			<code>df.fillna(0)</code></br>
			<code>df.fillna(0, subset=['a', 'b'])</code></br>
		</p>
		<h3>Dataframe modification</h3>
		<p>	
			<code>df.withColumnRenamed('old', 'new')</code></br>
			<code>df.withColumn('value', 1 / df.age)</code></br>
			<code>df.withColumn('logdisp', f.log(df.disp))</code></br>
			<code>df.withColumn("decision", f.when(f.col("dpid") == 1001708, True).otherwise(False))</code></br>
			<code>df.withColumn('cond', f.when(df.mpg > 20, 1).when(df.cyl == 6, 2).otherwise(3))</code></br>
			<code>df.drop('strenght')</code></br>
			<code>df.dropDuplicates(['age', 'name'])</code></br>
		</p>
		<h3>Dataframe aggregations</h3>
		<p>	
			<code>df.groupBy("gaid").agg(f.count("sid").alias("num_sessions"))</code></br>
			<code>df.groupBy('A', 'B').pivot('C').sum('D')</code></br>
		</p>
		<h3>Dataframe joins</h3>
		<p>	
			<code>df1.join(df2, on='key')</code></br>
			<code>df1.join(df2, df1.age == df2.age)</code></br>
		</p>
	</body>
</html>
